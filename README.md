# Internet Communication


Implemetation of a crawler downloading web sites from a web server using sockets splitted in three parts:

1)Web site creator: creating a directory (root_dir) of sites each one having some pages that refer to others inside the root_dir
(Shell script used)

2)Web server: server that gets HTTP requests and returns the appropriate answer

3)Web crawler: sends HTTP requests and downloads these which exist saving them at a specific folder

*Systems Programming* - May 2018
